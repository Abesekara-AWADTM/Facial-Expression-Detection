{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.24.3-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "     ---------------------------------------- 14.9/14.9 MB 2.8 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.24.3\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp38-cp38-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Downloading tensorflow_intel-2.12.0-cp38-cp38-win_amd64.whl (272.8 MB)\n",
      "     -------------------------------------- 272.8/272.8 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.0-cp38-cp38-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 3.1 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.22.4-cp38-cp38-win_amd64.whl (420 kB)\n",
      "     -------------------------------------- 420.6/420.6 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 2.7/2.7 MB 3.0 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp38-cp38-win_amd64.whl (35 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting jax>=0.3.15\n",
      "  Using cached jax-0.4.8.tar.gz (1.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda\\envs\\fyp_face_emotion\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\envs\\fyp_face_emotion\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (66.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda\\envs\\fyp_face_emotion\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\envs\\fyp_face_emotion\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.23.5-cp38-cp38-win_amd64.whl (14.7 MB)\n",
      "     ---------------------------------------- 14.7/14.7 MB 3.2 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda\\envs\\fyp_face_emotion\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Collecting scipy>=1.7\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "     ---------------------------------------- 42.2/42.2 MB 2.3 MB/s eta 0:00:00\n",
      "Collecting ml-dtypes>=0.0.3\n",
      "  Downloading ml_dtypes-0.1.0-cp38-cp38-win_amd64.whl (120 kB)\n",
      "     -------------------------------------- 120.2/120.2 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\chethiya\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.3.3-py3-none-any.whl (242 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\anaconda\\envs\\fyp_face_emotion\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (6.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chethiya\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\chethiya\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chethiya\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.2-cp38-cp38-win_amd64.whl (16 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda\\envs\\fyp_face_emotion\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.15.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.8-py3-none-any.whl size=1439795 sha256=fd4ac923a4f481fab67a09ee1b8890f039de966ba9128a90b779a3c51bca78d7\n",
      "  Stored in directory: c:\\users\\chethiya\\appdata\\local\\pip\\cache\\wheels\\45\\83\\1e\\3db22c5e1941c10e41c4f5cdf829b0a358146d4d0733d4a105\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, MarkupSafe, keras, grpcio, google-pasta, gast, certifi, cachetools, astunparse, absl-py, werkzeug, scipy, rsa, pyasn1-modules, opt-einsum, ml-dtypes, markdown, h5py, requests-oauthlib, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 certifi-2022.12.7 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.0 h5py-3.8.0 jax-0.4.8 keras-2.12.0 libclang-16.0.0 markdown-3.4.3 ml-dtypes-0.1.0 numpy-1.23.5 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.22.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 scipy-1.10.1 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 werkzeug-2.3.3 wrapt-1.14.1\n",
      "Collecting pillow\n",
      "  Downloading Pillow-9.5.0-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow\n",
      "Successfully installed pillow-9.5.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install numpy\n",
    "# !pip install tensorflow\n",
    "# !pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images will be rescaled by 1./255\n",
    "trin_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = trin_datagen.flow_from_directory(\n",
    "        'data/train',  # This is the source directory for training images\n",
    "        target_size=(48, 48),  # All images will be resized to 48x48\n",
    "        batch_size=64, \n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Flow validation images in batches of 128 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\fyp_emotion_detection\\Lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 1st convolution layer\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "# 2nd convolution layer\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "# 3rd convolution layer\n",
    "# emotion_model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "# emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# emotion_model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "# emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Flatten())\n",
    "\n",
    "# Fully connected layer 1st layer\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "\n",
    "emotion_model.add(Dense(7, activation='softmax')) # 7 because we have 7 classes {0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral}\n",
    "\n",
    "emotion_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "448/448 [==============================] - 373s 831ms/step - loss: 1.8027 - accuracy: 0.2606 - val_loss: 1.7121 - val_accuracy: 0.3341\n",
      "Epoch 2/50\n",
      "448/448 [==============================] - 205s 457ms/step - loss: 1.6313 - accuracy: 0.3643 - val_loss: 1.5468 - val_accuracy: 0.4092\n",
      "Epoch 3/50\n",
      "448/448 [==============================] - 213s 476ms/step - loss: 1.5285 - accuracy: 0.4143 - val_loss: 1.4632 - val_accuracy: 0.4474\n",
      "Epoch 4/50\n",
      "448/448 [==============================] - 212s 474ms/step - loss: 1.4544 - accuracy: 0.4432 - val_loss: 1.3956 - val_accuracy: 0.4724\n",
      "Epoch 5/50\n",
      "448/448 [==============================] - 216s 482ms/step - loss: 1.3896 - accuracy: 0.4704 - val_loss: 1.3514 - val_accuracy: 0.4851\n",
      "Epoch 6/50\n",
      "448/448 [==============================] - 219s 489ms/step - loss: 1.3374 - accuracy: 0.4916 - val_loss: 1.2939 - val_accuracy: 0.5106\n",
      "Epoch 7/50\n",
      "448/448 [==============================] - 223s 497ms/step - loss: 1.2970 - accuracy: 0.5089 - val_loss: 1.2718 - val_accuracy: 0.5119\n",
      "Epoch 8/50\n",
      "448/448 [==============================] - 223s 497ms/step - loss: 1.2595 - accuracy: 0.5253 - val_loss: 1.2437 - val_accuracy: 0.5271\n",
      "Epoch 9/50\n",
      "448/448 [==============================] - 233s 521ms/step - loss: 1.2286 - accuracy: 0.5345 - val_loss: 1.2225 - val_accuracy: 0.5293\n",
      "Epoch 10/50\n",
      "448/448 [==============================] - 224s 501ms/step - loss: 1.1936 - accuracy: 0.5519 - val_loss: 1.1983 - val_accuracy: 0.5391\n",
      "Epoch 11/50\n",
      "448/448 [==============================] - 212s 474ms/step - loss: 1.1684 - accuracy: 0.5608 - val_loss: 1.1807 - val_accuracy: 0.5474\n",
      "Epoch 12/50\n",
      "448/448 [==============================] - 210s 468ms/step - loss: 1.1423 - accuracy: 0.5723 - val_loss: 1.1724 - val_accuracy: 0.5534\n",
      "Epoch 13/50\n",
      "448/448 [==============================] - 203s 452ms/step - loss: 1.1177 - accuracy: 0.5814 - val_loss: 1.1533 - val_accuracy: 0.5589\n",
      "Epoch 14/50\n",
      "448/448 [==============================] - 194s 434ms/step - loss: 1.0951 - accuracy: 0.5899 - val_loss: 1.1424 - val_accuracy: 0.5631\n",
      "Epoch 15/50\n",
      "448/448 [==============================] - 195s 436ms/step - loss: 1.0721 - accuracy: 0.6001 - val_loss: 1.1491 - val_accuracy: 0.5590\n",
      "Epoch 16/50\n",
      "448/448 [==============================] - 194s 432ms/step - loss: 1.0479 - accuracy: 0.6085 - val_loss: 1.1224 - val_accuracy: 0.5756\n",
      "Epoch 17/50\n",
      "448/448 [==============================] - 194s 432ms/step - loss: 1.0254 - accuracy: 0.6192 - val_loss: 1.1105 - val_accuracy: 0.5777\n",
      "Epoch 18/50\n",
      "448/448 [==============================] - 197s 440ms/step - loss: 1.0008 - accuracy: 0.6292 - val_loss: 1.1000 - val_accuracy: 0.5836\n",
      "Epoch 19/50\n",
      "448/448 [==============================] - 195s 435ms/step - loss: 0.9774 - accuracy: 0.6360 - val_loss: 1.0991 - val_accuracy: 0.5829\n",
      "Epoch 20/50\n",
      "448/448 [==============================] - 194s 434ms/step - loss: 0.9586 - accuracy: 0.6441 - val_loss: 1.0932 - val_accuracy: 0.5872\n",
      "Epoch 21/50\n",
      "448/448 [==============================] - 193s 431ms/step - loss: 0.9360 - accuracy: 0.6540 - val_loss: 1.0940 - val_accuracy: 0.5845\n",
      "Epoch 22/50\n",
      "448/448 [==============================] - 193s 432ms/step - loss: 0.9152 - accuracy: 0.6610 - val_loss: 1.0773 - val_accuracy: 0.5936\n",
      "Epoch 23/50\n",
      "448/448 [==============================] - 193s 431ms/step - loss: 0.8946 - accuracy: 0.6672 - val_loss: 1.0760 - val_accuracy: 0.5981\n",
      "Epoch 24/50\n",
      "448/448 [==============================] - 193s 431ms/step - loss: 0.8720 - accuracy: 0.6814 - val_loss: 1.0822 - val_accuracy: 0.5944\n",
      "Epoch 25/50\n",
      "448/448 [==============================] - 193s 431ms/step - loss: 0.8477 - accuracy: 0.6865 - val_loss: 1.0685 - val_accuracy: 0.6025\n",
      "Epoch 26/50\n",
      "448/448 [==============================] - 194s 432ms/step - loss: 0.8251 - accuracy: 0.6957 - val_loss: 1.0758 - val_accuracy: 0.6030\n",
      "Epoch 27/50\n",
      "448/448 [==============================] - 194s 432ms/step - loss: 0.8005 - accuracy: 0.7102 - val_loss: 1.0646 - val_accuracy: 0.6073\n",
      "Epoch 28/50\n",
      "448/448 [==============================] - 194s 432ms/step - loss: 0.7853 - accuracy: 0.7126 - val_loss: 1.0658 - val_accuracy: 0.6052\n",
      "Epoch 29/50\n",
      "448/448 [==============================] - 193s 431ms/step - loss: 0.7607 - accuracy: 0.7220 - val_loss: 1.0685 - val_accuracy: 0.6056\n",
      "Epoch 30/50\n",
      "448/448 [==============================] - 196s 438ms/step - loss: 0.7359 - accuracy: 0.7340 - val_loss: 1.0709 - val_accuracy: 0.6105\n",
      "Epoch 31/50\n",
      "448/448 [==============================] - 195s 434ms/step - loss: 0.7114 - accuracy: 0.7410 - val_loss: 1.0905 - val_accuracy: 0.6056\n",
      "Epoch 32/50\n",
      "448/448 [==============================] - 195s 435ms/step - loss: 0.6945 - accuracy: 0.7441 - val_loss: 1.0806 - val_accuracy: 0.6122\n",
      "Epoch 33/50\n",
      "448/448 [==============================] - 194s 432ms/step - loss: 0.6739 - accuracy: 0.7556 - val_loss: 1.0737 - val_accuracy: 0.6124\n",
      "Epoch 34/50\n",
      "448/448 [==============================] - 194s 433ms/step - loss: 0.6489 - accuracy: 0.7626 - val_loss: 1.0879 - val_accuracy: 0.6124\n",
      "Epoch 35/50\n",
      "448/448 [==============================] - 194s 433ms/step - loss: 0.6273 - accuracy: 0.7731 - val_loss: 1.0902 - val_accuracy: 0.6165\n",
      "Epoch 36/50\n",
      "448/448 [==============================] - 194s 433ms/step - loss: 0.6070 - accuracy: 0.7791 - val_loss: 1.1000 - val_accuracy: 0.6169\n",
      "Epoch 37/50\n",
      "448/448 [==============================] - 196s 438ms/step - loss: 0.5973 - accuracy: 0.7827 - val_loss: 1.0918 - val_accuracy: 0.6164\n",
      "Epoch 38/50\n",
      "448/448 [==============================] - 197s 439ms/step - loss: 0.5690 - accuracy: 0.7923 - val_loss: 1.1027 - val_accuracy: 0.6232\n",
      "Epoch 39/50\n",
      "448/448 [==============================] - 176s 392ms/step - loss: 0.5516 - accuracy: 0.8001 - val_loss: 1.1062 - val_accuracy: 0.6205\n",
      "Epoch 40/50\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 0.5359 - accuracy: 0.8080 - val_loss: 1.1091 - val_accuracy: 0.6205\n",
      "Epoch 41/50\n",
      "448/448 [==============================] - 172s 385ms/step - loss: 0.5186 - accuracy: 0.8109 - val_loss: 1.1211 - val_accuracy: 0.6179\n",
      "Epoch 42/50\n",
      "448/448 [==============================] - 174s 388ms/step - loss: 0.5039 - accuracy: 0.8178 - val_loss: 1.1364 - val_accuracy: 0.6212\n",
      "Epoch 43/50\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 0.4848 - accuracy: 0.8249 - val_loss: 1.1376 - val_accuracy: 0.6212\n",
      "Epoch 44/50\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 0.4693 - accuracy: 0.8325 - val_loss: 1.1520 - val_accuracy: 0.6133\n",
      "Epoch 45/50\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 0.4553 - accuracy: 0.8367 - val_loss: 1.1499 - val_accuracy: 0.6212\n",
      "Epoch 46/50\n",
      "448/448 [==============================] - 172s 385ms/step - loss: 0.4391 - accuracy: 0.8414 - val_loss: 1.1922 - val_accuracy: 0.6176\n",
      "Epoch 47/50\n",
      "448/448 [==============================] - 172s 385ms/step - loss: 0.4228 - accuracy: 0.8481 - val_loss: 1.1796 - val_accuracy: 0.6236\n",
      "Epoch 48/50\n",
      "448/448 [==============================] - 172s 383ms/step - loss: 0.4105 - accuracy: 0.8532 - val_loss: 1.2195 - val_accuracy: 0.6211\n",
      "Epoch 49/50\n",
      "448/448 [==============================] - 172s 385ms/step - loss: 0.4024 - accuracy: 0.8549 - val_loss: 1.2090 - val_accuracy: 0.6173\n",
      "Epoch 50/50\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 0.3802 - accuracy: 0.8627 - val_loss: 1.2158 - val_accuracy: 0.6254\n"
     ]
    }
   ],
   "source": [
    "# emotion_model_info = emotion_model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=28709 // 64,\n",
    "#         epochs=50,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=7178 // 64)\n",
    "\n",
    "# training neural network\n",
    "emotion_model_info = emotion_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_json = emotion_model.to_json()\n",
    "with open(\"model/emotion_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "emotion_model.save_weights('model/emotion_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.6251044869422913\n"
     ]
    }
   ],
   "source": [
    "# evaluate mmodel\n",
    "scores = emotion_model.evaluate(validation_generator, verbose=0)\n",
    "print('Test accuracy', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(emotion_model, to_file='model/model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
